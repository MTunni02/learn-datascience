{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "EZwIXXrZsA_R"
   },
   "source": [
    "#### Rating and Ranking with Markov's Method:\n",
    "\n",
    "#### The Premier League case\n",
    "\n",
    "This is the __solution__ notebook.\n",
    "\n",
    "We will analyse Premier League results for these two interesting seasons; results have been downloaded from [www.footballwebpages.co.uk](https://www.footballwebpages.co.uk/premier-league):\n",
    "\n",
    "- the [2021 - 2022 season](https://www.footballwebpages.co.uk/premier-league/match-grid/2021-2022), and\n",
    "  \n",
    "- [2022 - 2023 season](https://www.footballwebpages.co.uk/premier-league/match-grid/2022-2023).\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nCJ_gouYi8xi"
   },
   "source": [
    "### Import necessary Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zp_ESJUYr5Mb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ME3iGaXyjC9Z"
   },
   "source": [
    "### Set Pandas and Numpy options for printing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "NGdD2i0HDYEN"
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=1000)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.colheader_justify', 'center')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "U5dTWY8jij0H"
   },
   "source": [
    "### Premier League winners:\n",
    "\n",
    "*   **2021 - 2022**: Manchester City (1-point gap from Liverpool that finished second)\n",
    "  \n",
    "*   **2022 - 2023**: Manchester City (5-points gap from Arsenal that finished second)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "TeKm7bZiichq"
   },
   "source": [
    "### File names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "OFBPvjCLhx99"
   },
   "outputs": [],
   "source": [
    "# League table files\n",
    "premier_league_table_2017_2018 = \"./data/2017_2018_LeagueTable.csv\"\n",
    "premier_league_table_2018_2019 = \"./data/2018_2019_LeagueTable.csv\"\n",
    "premier_league_table_2019_2020 = \"./data/2019_2020_LeagueTable.csv\"\n",
    "premier_league_table_2020_2021 = \"./data/2020_2021_LeagueTable.csv\"\n",
    "premier_league_table_2021_2022 = \"./data/2021_2022_LeagueTable.csv\"\n",
    "premier_league_table_2022_2023 = \"./data/2022_2023_LeagueTable.csv\"\n",
    "\n",
    "# Match grid files\n",
    "premier_league_match_grid_2017_2018 = \"./data/2017_2018_MatchGrid.csv\"\n",
    "premier_league_match_grid_2018_2019 = \"./data/2018_2019_MatchGrid.csv\"\n",
    "premier_league_match_grid_2019_2020 = \"./data/2017_2018_MatchGrid.csv\"\n",
    "premier_league_match_grid_2020_2021 = \"./data/2020_2021_MatchGrid.csv\"\n",
    "premier_league_match_grid_2021_2022 = \"./data/2021_2022_MatchGrid.csv\"\n",
    "premier_league_match_grid_2022_2023 = \"./data/2022_2023_MatchGrid.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEeBJchejTa6"
   },
   "source": [
    "### Set current working data files and next season files\n",
    "\n",
    "Hint: Change these variables in case you would like to rate / rank teams based on a different season and check the estimates against the actual rankings of the following season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "mj-LLbynjFT2"
   },
   "outputs": [],
   "source": [
    "# Current (working) season\n",
    "current_league_table_file = premier_league_table_2021_2022\n",
    "\n",
    "current_match_grid_file = premier_league_match_grid_2021_2022\n",
    "\n",
    "current_season = \"2021 - 2022\"\n",
    "\n",
    "# Merged results of current season from Massey and Keener\n",
    "merged_results_2021_2022 = \"./data/2021_2022_MergedResults.csv\"\n",
    "\n",
    "# Next season\n",
    "coming_league_table_file = premier_league_table_2022_2023\n",
    "\n",
    "coming_match_grid_file = premier_league_match_grid_2022_2023\n",
    "\n",
    "coming_season = \"2022 - 2023\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Markov's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### For Markov we need again the match grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Each match entry is in the format =\"GH-GA\" (except from NaN in diagonal).\n",
    "# GH are goals scored by the home team, and GA are goals scored by the away team\n",
    "# Below, we read the match grid CSV and remove '=' and '\"'\n",
    "\n",
    "match_grid = (\n",
    "    pd.read_csv(current_match_grid_file, dtype=str, index_col=0)\n",
    "    .replace('\"' , '', regex=True)\n",
    "    .replace('=' , '', regex=True)\n",
    "    .fillna(\"0-0\")\n",
    "    )\n",
    "\n",
    "match_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Create Markov's V matrix\n",
    "\n",
    "Below is a refresher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We remember that $V_{n \\times n}$  where $v_{ij}:$ total goals conceded by $i$ to $j$\n",
    "\n",
    "\n",
    "Here $n=$ number of teams in the league"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Create Markov's S matrix\n",
    "\n",
    "Below is another refresher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "$S_{n \\times n}$ where $s_{ij}:$ proportion of goals team i conceded to team over the total goals team i conceded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Exercise 1: Complete the code to calculate Markov's V and S matrices\n",
    "\n",
    "#### Step-by-step:\n",
    "\n",
    "1.   Parse scores. Example: \"3-2\". The home team scored 3 goals and the away team 2.\n",
    "\n",
    "   Hint: Pandas [applymap documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.applymap.html)\n",
    "\n",
    "2.   Match every team's home match with the respective away match against the same opponent.\n",
    "\n",
    "   Hint: The home match of team *i* against *j* is element *ij*. The respective away match is element *ji* - row and column indexes are swapped..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Parse score and get goals conceded at home\n",
    "home_goals_ij = lambda score: int(score.split(\"-\")[1])\n",
    "\n",
    "all_home_goals_ij = match_grid.applymap(home_goals_ij)\n",
    "\n",
    "# Parse score and get goals conceded away\n",
    "# The grid is transposed to match every team's respective\n",
    "# home and away matches\n",
    "away_goals_ij = lambda score: int(score.split(\"-\")[0])\n",
    "\n",
    "all_away_goals_ij = match_grid.T.applymap(away_goals_ij)\n",
    "\n",
    "# Sum goals conceded\n",
    "V_dataframe = all_home_goals_ij + all_away_goals_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# row_sums: Sum of goals each team conceded\n",
    "row_sums = V_dataframe.sum(axis=1)\n",
    "\n",
    "# Create S matrix\n",
    "S_dataframe = V_dataframe.div(row_sums, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Create transition and counter dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dictionary with teams as keys and lists of probabilities as values\n",
    "# Each list represents a probability of moving from current team\n",
    "# to another team of the league (fair-weather fan logic)\n",
    "transit_dict = S_dataframe.T.to_dict(orient = \"list\")\n",
    "\n",
    "teams = S_dataframe.columns.tolist()\n",
    "\n",
    "# Dictionary with teams as keys and number of visits as values\n",
    "counter_dict = {team: 0 for team in teams}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Markov's simulation of the fair-weather fan\n",
    "\n",
    "\n",
    "By moving towards the team that appears strongest at the moment, the fair-weather fan will end up indicating, with his/her support, the overall best team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many teams in the league?\n",
    "n_teams = 20\n",
    "\n",
    "\n",
    "How many iterations to run?\n",
    "N = 100_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize process by randomly selecting a team\n",
    "curr_team = np.random.choice(teams)\n",
    "counter_dict[curr_team] += 1\n",
    "\n",
    "# Run the simulation\n",
    "for i in range(N):\n",
    "    probs = transit_dict[curr_team]\n",
    "    curr_team = np.random.choice(teams, p = probs)\n",
    "    counter_dict[curr_team] += 1\n",
    "\n",
    "# Get the ratings\n",
    "ratings = [count / (N + 1) for count in counter_dict.values()]\n",
    "\n",
    "markov_df = (\n",
    "    pd.DataFrame(ratings, index = teams, columns=[\"Markov_Rating\"])\n",
    "    .sort_values(by=\"Markov_Rating\", ascending=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Use a MinMaxScaler to scale Markov ratings between 0 and 100 for plotting.\n",
    "\n",
    "Please see the relative [sklearn MinMaxScaler documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Scale the ratings between 100 (top team) and 0 (weakest team).\n",
    "\n",
    "# MinMaxScaler accepts a tuple (min, max) as input argument to define the range.\n",
    "min_max_scaler = MinMaxScaler((0, 100))\n",
    "\n",
    "markov_df[\"Markov_Scaled_Rating\"] = min_max_scaler.fit_transform(markov_df.loc[:, \"Markov_Rating\"].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Add Markov ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Add Markov ranking\n",
    "markov_df[\"Markov_Ranking\"] = np.arange(1, 21)\n",
    "\n",
    "markov_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Add Markov results to the match grid table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "match_grid = match_grid.join(markov_df)\n",
    "\n",
    "match_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Import the league table to get actual rankings and points scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read the league table data - skip the first row\n",
    "league_table = pd.read_csv(current_league_table_file, skiprows = 1)\n",
    "\n",
    "league_table[\"Actual_Ranking\"] = np.arange(1, n_teams + 1)\n",
    "\n",
    "league_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### We keep only teams, actual ranking and points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "required_cols = [\"Unnamed: 1\", \"Pts\", \"Actual_Ranking\"]\n",
    "\n",
    "renaming = {\"Unnamed: 1\": \"Teams\", \"Pts\": \"Points\"}\n",
    "\n",
    "# Make a copy of the league table, keeping only the necessary columns renamed\n",
    "# Index is reset as the teams for the table join below\n",
    "league_table = (\n",
    "    league_table\n",
    "    .loc[ :, required_cols]\n",
    "    .copy()\n",
    "    .rename(columns=renaming)\n",
    "    .set_index(\"Teams\")\n",
    ")\n",
    "\n",
    "league_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Join the match grid that holds Markov ratings with the league table and the actual ratings based on team names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "match_grid = match_grid.join(league_table)\n",
    "\n",
    "match_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Keep Markov rating and ranking from the match grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cols_to_keep = [\n",
    "    \"Markov_Rating\",\n",
    "    \"Markov_Scaled_Rating\",\n",
    "    \"Markov_Ranking\"\n",
    "    ]\n",
    "\n",
    "# Data needed from Markov output - sort by actual ranking first\n",
    "data_to_keep = (\n",
    "    match_grid\n",
    "    .sort_values(\"Actual_Ranking\", ascending = True)\n",
    "    .loc[:, cols_to_keep]\n",
    "    .copy()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Import merged data with Massey and Keener results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Use Teams column as index to join it later with Markov\n",
    "merged_results = pd.read_csv(merged_results_2021_2022, index_col = \"Teams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Merge Markov results with Massey and Keener results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Merge the data\n",
    "merged_results = merged_results.join(data_to_keep)\n",
    "\n",
    "merged_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Plot Markov's scaled rating and ranking side by side with actual ranking and points scored\n",
    "\n",
    "Documentation for [matplotlib.pyplot horizontal bar plots](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.barh.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize grid of plots\n",
    "figure, axis = plt.subplots(nrows = 1, ncols = 2, figsize = (12, 4), dpi = 160)\n",
    "\n",
    "# Plot Keener scaled rating - plot 0, row 0\n",
    "axis[0].barh(\n",
    "    match_grid[\"Markov_Ranking\"],\n",
    "    match_grid[\"Markov_Scaled_Rating\"],\n",
    "    height = 0.6, align = 'center'\n",
    "    )\n",
    "\n",
    "# Configure y axis\n",
    "axis[0].set_yticks(\n",
    "    match_grid[\"Markov_Ranking\"],\n",
    "    labels = match_grid.index,\n",
    "    fontsize = 7\n",
    "    )\n",
    "\n",
    "axis[0].invert_yaxis()  # labels read top-to-bottom\n",
    "\n",
    "# X-axis and title\n",
    "axis[0].tick_params(axis = \"x\", labelsize = 6)\n",
    "axis[0].set_xlabel('Markov Scaled Rating', fontsize = 8)\n",
    "axis[0].set_title(f'Season {current_season} Markov Scaled Rating', fontsize = 8)\n",
    "\n",
    "# Plot actual ranking and point scored - plot 1, row 0\n",
    "axis[1].barh(\n",
    "    match_grid[\"Actual_Ranking\"],\n",
    "    match_grid[\"Points\"],\n",
    "    height = 0.6, align = 'center'\n",
    "    )\n",
    "\n",
    "# Configure y axis\n",
    "axis[1].set_yticks(\n",
    "    match_grid[\"Actual_Ranking\"],\n",
    "    labels = match_grid.index,\n",
    "    fontsize = 7\n",
    "    )\n",
    "axis[1].invert_yaxis()  # labels read top-to-bottom\n",
    "\n",
    "# X-axis and title\n",
    "axis[1].tick_params(axis = \"x\", labelsize = 6)\n",
    "axis[1].set_xlabel('Actual Points', fontsize = 8)\n",
    "axis[1].set_title(f'Season {current_season} Points Scored', fontsize = 8)\n",
    "\n",
    "# Use 'tight_layout' to avoid overlapping text\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "oGKL08ROx59x"
   },
   "source": [
    "### Get rankings from all methods in a new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "la5TT3yB85s9",
    "outputId": "31b2c79f-fb57-4b08-84f0-3258a2cfaacc",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "rankings = [\n",
    "    \"Actual_Ranking\",\n",
    "    \"Massey_Ranking\",\n",
    "    \"Keener_Ranking\",\n",
    "    \"Markov_Ranking\"\n",
    "    ]\n",
    "\n",
    "ranks_df = merged_results.loc[:, rankings].copy()\n",
    "ranks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "m6JN4kBz9c3L",
    "outputId": "f544fa85-3bf2-4660-9bb9-20ef4f6511d2",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ranks_df.corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jqWQQVATyUny"
   },
   "source": [
    "#### Import the table of the subsequent season to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "2Uou9aDN-C0h"
   },
   "outputs": [],
   "source": [
    "# Read the league table data - skip the first row\n",
    "next_league_table = pd.read_csv(coming_league_table_file, skiprows = 1)\n",
    "\n",
    "next_league_table[\"Actual_Ranking\"] = np.arange(1, 21)\n",
    "\n",
    "# Uncomment if you want to see the raw table\n",
    "# league_table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wCOTW-1Mym5-"
   },
   "source": [
    "#### Keep necessary columns and rename them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 897
    },
    "id": "1QFVh7Rl-86S",
    "outputId": "69abb216-c16a-4b7c-ebd4-34f6e4eb3f6a",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "required_cols = [\"Unnamed: 1\", \"P.2\", \"W.2\", \"D.2\", \"L.2\", \"F\", \n",
    "                 \"A\", \"+/-\", \"Pts\", \"Actual_Ranking\"]\n",
    "\n",
    "renaming = {\n",
    "    \"Unnamed: 1\": \"Teams\", \n",
    "    \"P.2\": \"Total_Matches_Played\", \n",
    "    \"W.2\": \"Total_Wins\",\n",
    "    \"D.2\": \"Total_Draws\",\n",
    "    \"L.2\": \"Total_Losses\",\n",
    "    \"F\": \"Goals_Scored\",\n",
    "    \"A\": \"Goals_Conceded\",\n",
    "    \"+/-\": \"Goal_Difference\",\n",
    "    \"Pts\": \"Points\"\n",
    "    }\n",
    "\n",
    "# Make a copy of the league table, keeping only the necessary columns renamed\n",
    "next_league_table = (\n",
    "    next_league_table\n",
    "    .loc[:, required_cols]\n",
    "    .copy()\n",
    "    .rename(columns = renaming)\n",
    ")\n",
    "\n",
    "next_league_table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "s1-bhfIzy0Ww"
   },
   "source": [
    "#### Recall estimated rankings from Massey, Keener and Markov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "_XCcTIhj_DtS",
    "outputId": "aca14fe5-10a2-4d34-ddb7-e26784b0495f",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ranks_df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
